## Directional Gaussian smoothing (DGS) for blackbox optimization
This repository contains Python code for testing Directional Gaussian smoothing (DGS) method on high-dimensional benchmark functions. This method was first introduced in the paper [*A Novel Evolution Strategy with Directional Gaussian Smoothing for Blackbox Optimization*](https://arxiv.org/pdf/2002.03001.pdf) by Jiaxin Zhang, Hoang Tran, Dan Lu and Guannan Zhang. 

### Features
- Directionally smoothing objective functions with Gaussian kernel for nonlocal exploration in each direction  
- Gauss-Hermite quadrature for approximating DGS gradient
- Backtracking line search for adaptively updating smoothing radius and step size 
- (Optional) Random generation of smoothing directions to enhance exploration 

### Benchmark functions 

### Related papers 

1. J. Zhang, H. Tran, D. Lu, G. Zhang, [A Novel Evolution Strategy with Directional Gaussian Smoothing for Blackbox Optimization](https://arxiv.org/pdf/2002.03001.pdf), submitted, 2020. 
2. H. Tran, G. Zhang, AdaDGS: An adaptive black-box optimization method with a nonlocal directional Gaussian smoothing gradient, submitted, 2020. 

<a id="id1">fdfd</a> 

<a id="id2">fdfd</a> 

<a id="id3">fdfd</a> 

Here is `some code` in the middle of a sentence.
```
This is
a block
Git and GitHub 192
of code
```
Here is how you make [a link](https://www.wikiped\ ia.org/).
![This is an image.](https://github.com/yihui/xar\ ingan/releases/download/v0.0.2/karl-moustache.jpg\ )

